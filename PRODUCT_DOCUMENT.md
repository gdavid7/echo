# Product Document: AI Dental Intake Assistant

## 1. Overview

This document outlines the architecture and functionality of the AI Dental Intake Assistant, a web-based prototype designed to streamline the patient intake process for dental offices.

The application provides a voice-driven conversational interface where a patient can describe their symptoms and history in natural language. An AI assistant, powered by OpenAI's GPT-4o, guides the conversation, and the entire interaction happens through spoken dialogue. Once the intake conversation is complete, the system generates a concise clinical summary for the dentist.

This project is built on a containerized, microservice architecture to ensure scalability and maintainability.

## 2. Core Features

*   **Voice-First Interface**: A real-time, voice-driven interface for patients to interact with an AI assistant.
*   **Speech-to-Text Transcription**: User's spoken words are transcribed in real-time using OpenAI's Whisper model.
*   **AI-Powered Conversation**: The assistant's responses and questions are dynamically generated by GPT-4o, making the conversation feel natural and context-aware.
*   **Text-to-Speech Synthesis**: The AI's text replies are converted into natural-sounding speech using OpenAI's TTS model and played back to the user.
*   **Stateful Sessions**: The application maintains the context of the conversation for each user session.
*   **Automated Clinical Summary**: At the conclusion of the chat, the system automatically generates a structured summary of the conversation, formatted for a clinician's review.

## 3. System Architecture

The application is composed of five distinct microservices, orchestrated by Docker Compose. This separation of concerns allows for independent development, scaling, and deployment of each component.

```
+-----------------+      +--------------------------+      +------------------------+
|                 |----->|   transcription_service  |----->|   conversation_service |
|                 |      +--------------------------+      +------------------------+
|   api_gateway   |                                                    |
| (Orchestrator)  |                                                    |
|                 |      +--------------------------+      +------------------------+
|                 |<-----|        tts_service       |<-----|                        |
|                 |      +--------------------------+      | (AI text reply)        |
+-----------------+                                      |                        |
        ^                                                |                        |
        |                                                v                        |
        |                                      +---------------------+            |
        +--------------------------------------|   summary_service   |<-----------+
                                               +---------------------+
```

*   **`api_gateway`**
    *   **Description**: The main entry point for the application. It serves the frontend web interface, manages user sessions, and acts as a request orchestrator for the entire voice-to-voice flow.
    *   **Port**: `5000`
*   **`transcription_service`**
    *   **Description**: A worker that receives raw audio data from the user and uses the OpenAI Whisper API to convert it into text.
*   **`conversation_service`**
    *   **Description**: A stateless worker responsible for advancing the conversation. It receives the transcribed text and the chat history, then uses the OpenAI GPT-4o API to generate the next appropriate question or response from the assistant.
*   **`tts_service`**
    *   **Description**: A worker that receives the AI's text-based reply and uses the OpenAI TTS API to generate audible speech audio.
*   **`summary_service`**
    *   **Description**: A stateless worker that generates the final clinical summary. It receives the complete conversation log and uses the OpenAI API to produce a structured, easy-to-read summary.

## 4. Technology Stack

*   **Backend**: Python 3.9, Flask
*   **Frontend**: HTML5, CSS3, JavaScript (with MediaRecorder API)
*   **AI Engine**: OpenAI (GPT-4o, Whisper, TTS)
*   **Containerization**: Docker, Docker Compose
*   **WSGI Server**: Gunicorn

## 5. Setup and Usage

### Prerequisites
*   Docker and Docker Compose installed on your local machine.
*   A valid OpenAI API key with sufficient credits.
*   A working microphone connected to your computer.
*   A modern web browser that supports the MediaRecorder API (e.g., Chrome, Firefox).

### Running the Application

1.  **Create `.env` file**: Create a file named `.env` in the root directory of the project.
2.  **Set API Key**: Add your OpenAI API key to the `.env` file in the following format:
    ```
    OPENAI_API_KEY=sk-YourActualKeyHere...
    ```
3.  **Build and Run Containers**: Open a terminal in the project's root directory and run the following command:
    ```bash
    docker compose up --build
    ```
    This command will build the Docker images for each service and start the application.

4.  **Access the Assistant**: Open your web browser and navigate to:
    [http://localhost:5000](http://localhost:5000)
    Your browser will likely prompt you for microphone access. Please grant permission.

You can now interact with the dental intake assistant by clicking the microphone button to start and stop recording.
